{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural Language Processing (NLP)- TEXT Manipulation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMlHWjNEWLrQthMOIb3sG/A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abidshafee/google.colaboratory_projects/blob/master/Natural_Language_Processing_(NLP)_TEXT_Manipulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClrjGWcqlTRV",
        "colab_type": "text"
      },
      "source": [
        "## NLP In Python\n",
        "**Python Libraries for Data NLP**: *pandas, sklearn, renltk, TextBlob, gensim* **Statistical Analysis** and  **Math** operation such as: cleaning data, **EDA or Exploratory Data Analysis** *for word count*, and Finally **NLP** *for sentiment analysis, topic modeling, and text generation. * **Next Communication** - **Design** *inclludes scope, visualization, extract insight*, **Domain** *Expertise*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_Ruf819n4pF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Science Approaches\n",
        "# 1 - raise a question \n",
        "# 2 - data gathering (web scraping) and cleaning\n",
        "#       python library involves in webscraping are: requests (make http request get data from the web)\n",
        "#       beautiful soup (parse html documents extract parts of a website)\n",
        "#       pickle (serialize objects and save the data)\n",
        "#       For cleaning pandas dataframe\n",
        "# 3 - eda or Exploratory Data Analysis\n",
        "# 4 - techniques\n",
        "# 5 - insights"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcymGKp1OWx1",
        "colab_type": "text"
      },
      "source": [
        "## Web Scraping - Data Gathering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KkGT6lWstiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from urllib.request import urlopen as uReq\n",
        "import requests as uReq\n",
        "from bs4 import BeautifulSoup as soup\n",
        "import nltk.corpus as nt\n",
        "import nltk.tokenize as tk"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqP_7PXSPNnZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e3833d6-10f4-4d58-affc-948e6ec21432"
      },
      "source": [
        "live_price_url = 'https://finance.yahoo.com/quote/EURUSD=X?p=EURUSD=X&.tsrc=fin-srch'\n",
        "headers = {\n",
        "    \"User-Agent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'\n",
        "}\n",
        "news_url = 'https://finance.yahoo.com/news/economic-data-puts-loonie-focus-022354695.html'\n",
        "\n",
        "# opening connection and grabing webdata\n",
        "#webClient = uReq(test_url)\n",
        "\n",
        "webClient = uReq.get(test_url, headers=headers)\n",
        "# parsing the html\n",
        "webPage = soup(webClient.text, 'lxml')\n",
        "\n",
        "# find specific content in webpage\n",
        "\n",
        "\"\"\"\n",
        "the find() method returns only the first tag that matches the argument\n",
        "\"\"\"\n",
        "\n",
        "# find_all returns a list of all the tags that matches the argument\n",
        "m_content_live_price = webPage.find_all('div', {'class':'My(6px) Pos(r) smartphone_Mt(6px)'})[0].find('span').text\n",
        "# main_div = content.div.article\n",
        "# article = main_div.article\n",
        "\n",
        "# para = content.find('div', class_='canvas-body Wow(bw) Cl(start) Mb(20px) Lh(30px) Fz(18px) C(#000) D(i)')\n",
        "\n",
        "# find a specific class in a webpage\n",
        "# classContent = content.find('p', class_='canvas-atom canvas-text Mb(1.0em) Mb(0)--sm Mt(0.8em)--sm')\n",
        "# this code will return div with currency class\n",
        "# this way we can find other attributes such as ids as well\n",
        "\n",
        "# print(content.prettify())\n",
        "# print(classContent.text)\n",
        "# print(main_div)\n",
        "print('eurusd-now: ', m_content_live_price)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eurusd-now:  1.1447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjRMIpaVahpe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3c3045dd-599b-4975-de9b-a53b36136c81"
      },
      "source": [
        "webClient2 = uReq.get(news_url)\n",
        "newsPage = soup(webClient2.text)\n",
        "\n",
        "news_article = newsPage.find_all('article', {'itemprop' :'articleBody'})[0].find('p')\n",
        "print(news_article)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<p class=\"canvas-atom canvas-text Mb(1.0em) Mb(0)--sm Mt(0.8em)--sm\" content='It was a relatively busy start to the day on the &lt;a href=\"https://www.fxempire.com/tools/economic-calendar\" target=\"_blank\" rel=\"nofollow noopener\"&gt;economic calendar&lt;/a&gt;. The Japanese Yen was back in action along with the Aussie Dollar.' data-reactid=\"20\" type=\"text\">It was a relatively busy start to the day on the <a href=\"https://www.fxempire.com/tools/economic-calendar\" rel=\"nofollow noopener\" target=\"_blank\">economic calendar</a>. The Japanese Yen was back in action along with the Aussie Dollar.</p>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCSp_hdbS5Nc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "headline = content.h1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5n76d5xB8Ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(headline.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqwvPvx-B-Vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}