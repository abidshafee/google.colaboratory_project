{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP - Natural Language Processing Using TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPkMTyzcC7vQxrMLFrnhKtN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abidshafee/google.colaboratory_projects/blob/master/NLP_Natural_Language_Processing_Using_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmy1OmLTNRIW",
        "colab_type": "text"
      },
      "source": [
        "# Tokenization\n",
        "api involves: **Tokenizer** from **tensorflow->compat.v2->keras->preprocessing.txt**\n",
        "\n",
        "Given sentences encoding into numbers is calles Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYDGN2atQPZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.compat.v2.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.txt import Tokenizer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdSK87gTNPQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = ['The first step in sentence classification is to represent variable-length sentences using neural networks.', 'In this section, I’m going to present the concept of recurrent neural networks (RNNs), one of the most important concepts in deep NLP.', 'Many modern NLP models use RNNs in some way.', 'I’ll explain why they’re important, what they do, and introduce their simplest variant.']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5YSKnz5Yxol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=100, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "# print(word_index)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EZP9IKpaRpY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "06f65c88-5803-4148-e59c-b292855976b7"
      },
      "source": [
        "word_index.keys()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['<OOV>', 'in', 'the', 'to', 'neural', 'networks', 'of', 'rnns', 'important', 'nlp', 'first', 'step', 'sentence', 'classification', 'is', 'represent', 'variable', 'length', 'sentences', 'using', 'this', 'section', 'i’m', 'going', 'present', 'concept', 'recurrent', 'one', 'most', 'concepts', 'deep', 'many', 'modern', 'models', 'use', 'some', 'way', 'i’ll', 'explain', 'why', 'they’re', 'what', 'they', 'do', 'and', 'introduce', 'their', 'simplest', 'variant'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FGox-YXyl1x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "39bf7fde-1ee9-47b7-a20d-ece3770b1272"
      },
      "source": [
        "word_index.values()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf-BKLTKxOTX",
        "colab_type": "text"
      },
      "source": [
        "# Organizing text by Sequencing - Turning Sentences into data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXKts2FbbmWW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cbbf0b02-9450-4440-b118-b0a136329403"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print(sequences)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3, 11, 12, 2, 13, 14, 15, 4, 16, 17, 18, 19, 20, 5, 6], [2, 21, 22, 23, 24, 4, 25, 3, 26, 7, 27, 5, 6, 8, 28, 7, 3, 29, 9, 30, 2, 31, 10], [32, 33, 10, 34, 35, 8, 2, 36, 37], [38, 39, 40, 41, 9, 42, 43, 44, 45, 46, 47, 48, 49]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsyJy28E4iFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "615b6864-fa6d-44b7-d688-32cd939324ec"
      },
      "source": [
        "# pad_sequences() is a method to handle sentences of different lengths\n",
        "# best way to handle sentence length is using raggedtensor, we might discuss it in another scope\n",
        "# but for simplicity we uses here the pad_sequence() to deal with sentence length\n",
        "padded = pad_sequences(sequences)\n",
        "print(padded)\n",
        "\n",
        "# pad_sequences accept parameters are follows: \n",
        "#  - padding='post' - will add 0s after the sentences\n",
        "#  - maxlen=5 - maxlen parameter specify the desire lengh\n",
        "#  - truncating='post' - specify the choping off the later post if sentence exided 'maxlen'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  0  0  0  0  0  3 11 12  2 13 14 15  4 16 17 18 19 20  5  6]\n",
            " [ 2 21 22 23 24  4 25  3 26  7 27  5  6  8 28  7  3 29  9 30  2 31 10]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 32 33 10 34 35  8  2 36 37]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 38 39 40 41  9 42 43 44 45 46 47 48 49]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qODYjsFnGAA5",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis - recognize sentiment in text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "905vSPop9dwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-_OKs1QOn__",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1f8c0db0-e422-46ea-94fd-4e309dc792fc"
      },
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ed30e75f-0d02-4c8d-8a3e-556453307d01\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ed30e75f-0d02-4c8d-8a3e-556453307d01\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sarcasm.json to sarcasm.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s12aJIZDO9ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('sarcasm.json', 'r') as f:\n",
        "  datastore = json.load(f)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29awEkOpPcTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = []\n",
        "labels = []\n",
        "urls = []\n",
        "\n",
        "for item in datastore:\n",
        "  sentences.append(item['headline'])\n",
        "  labels.append(item['is_sarcastic'])\n",
        "  urls.append(item['article_link'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-82hi1n2Pof7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentences"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQTaIGPtS6Ts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6459a94-1f2e-4569-d39d-c63b79ad0768"
      },
      "source": [
        "# labels\n",
        "# urls\n",
        "len(labels)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26709"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw2iAddzVT_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WBawwW65f30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now turning the sentences sequence of token\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "paded = pad_sequences(sequences, padding='post')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQY1jPcD9jmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84430e99-c8d2-46b4-faa3-033a62458eb4"
      },
      "source": [
        "len(sequences)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26709"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19hDmdqn5sFw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "98d89e10-5478-4fe6-ec59-185d502040b6"
      },
      "source": [
        "paded[1]\n",
        "# paded.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   4, 8435, 3338, 2746,   22,    2,  166, 8436,  416, 3112,    6,\n",
              "        258,    9, 1002,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVyNGcq48_MQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03d81bd6-9dd8-46bf-a345-a0025f1276f1"
      },
      "source": [
        "paded.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26709, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FSWRcwb6tOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now spliting data into traning and testing sets\n",
        "# let training_size = 80% of data; 26709*80% using python slicing\n",
        "\n",
        "training_size = 21000\n",
        "\n",
        "training_sentences = sentences[:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "\n",
        "# spliting labels into training and testing sets\n",
        "training_labels = labels[:training_size]\n",
        "testing_labels = labels[training_size:]\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW2Q23dSDc6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now tekenize trainig and testing set seperately\n",
        "\n",
        "tokenizer = Tokenizer(num_words=training_size, oov_token=None)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwLhugV9VXjO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6f6907cb-f786-4281-fee3-56516b378d89"
      },
      "source": [
        "# word_index\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_paded = pad_sequences(training_sequences)\n",
        "training_paded"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,     5,  2711,  9172],\n",
              "       [    0,     0,     0, ...,   254,     8,   945],\n",
              "       [    0,     0,     0, ...,    44,     1,  9173],\n",
              "       ...,\n",
              "       [    0,     0,     0, ..., 12473,  5960,   496],\n",
              "       [    0,     0,     0, ...,     3,   363,   311],\n",
              "       [    0,     0,     0, ...,    19,  3769,   937]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn11YXKqXiXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6bf750e9-3d53-4feb-a112-3b77c91aa4e6"
      },
      "source": [
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_paded = pad_sequences(testing_sequences)\n",
        "testing_paded"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,   369,  1316,  5075],\n",
              "       [    0,     0,     0, ...,     0,     0,  5478],\n",
              "       [    0,     0,     0, ..., 13430,     7, 14891],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,     0,     8,    67],\n",
              "       [    0,     0,     0, ...,  1724,  3788,  3483],\n",
              "       [    0,     0,     0, ...,     5,     3,   800]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGed_DlsiMOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# converting to numpy array explicitely for recent version of tf\n",
        "training_paded = np.array(training_paded)\n",
        "training_labels = np.array(training_labels)\n",
        "testing_paded = np.array(testing_paded)\n",
        "testing_labels = np.array(testing_labels)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGtExJSAaD5_",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS5ymXZOYz5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(training_size, output_dim=11),\n",
        "                             tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                             tf.keras.layers.Dense(21, activation = 'relu'),\n",
        "                             tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8voEWYCickQJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "9db5c986-8099-4f51-a2bc-36ff38c2c5d6"
      },
      "source": [
        "epoch_no = 22\n",
        "training_texts = model.fit(training_paded, training_labels, epochs=epoch_no,\n",
        "                           validation_data=(testing_paded, testing_labels), verbose=2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/22\n",
            "657/657 - 3s - loss: 0.5950 - accuracy: 0.6805 - val_loss: 0.4396 - val_accuracy: 0.8364\n",
            "Epoch 2/22\n",
            "657/657 - 2s - loss: 0.3380 - accuracy: 0.8700 - val_loss: 0.3516 - val_accuracy: 0.8537\n",
            "Epoch 3/22\n",
            "657/657 - 2s - loss: 0.2405 - accuracy: 0.9100 - val_loss: 0.3361 - val_accuracy: 0.8564\n",
            "Epoch 4/22\n",
            "657/657 - 2s - loss: 0.1821 - accuracy: 0.9347 - val_loss: 0.3409 - val_accuracy: 0.8574\n",
            "Epoch 5/22\n",
            "657/657 - 2s - loss: 0.1411 - accuracy: 0.9517 - val_loss: 0.3589 - val_accuracy: 0.8543\n",
            "Epoch 6/22\n",
            "657/657 - 2s - loss: 0.1105 - accuracy: 0.9651 - val_loss: 0.3880 - val_accuracy: 0.8501\n",
            "Epoch 7/22\n",
            "657/657 - 2s - loss: 0.0871 - accuracy: 0.9730 - val_loss: 0.4138 - val_accuracy: 0.8492\n",
            "Epoch 8/22\n",
            "657/657 - 2s - loss: 0.0683 - accuracy: 0.9806 - val_loss: 0.4597 - val_accuracy: 0.8439\n",
            "Epoch 9/22\n",
            "657/657 - 2s - loss: 0.0541 - accuracy: 0.9858 - val_loss: 0.4890 - val_accuracy: 0.8432\n",
            "Epoch 10/22\n",
            "657/657 - 2s - loss: 0.0424 - accuracy: 0.9894 - val_loss: 0.5431 - val_accuracy: 0.8373\n",
            "Epoch 11/22\n",
            "657/657 - 2s - loss: 0.0335 - accuracy: 0.9916 - val_loss: 0.5907 - val_accuracy: 0.8346\n",
            "Epoch 12/22\n",
            "657/657 - 2s - loss: 0.0259 - accuracy: 0.9945 - val_loss: 0.6393 - val_accuracy: 0.8329\n",
            "Epoch 13/22\n",
            "657/657 - 2s - loss: 0.0200 - accuracy: 0.9965 - val_loss: 0.6829 - val_accuracy: 0.8294\n",
            "Epoch 14/22\n",
            "657/657 - 2s - loss: 0.0155 - accuracy: 0.9974 - val_loss: 0.7367 - val_accuracy: 0.8245\n",
            "Epoch 15/22\n",
            "657/657 - 2s - loss: 0.0120 - accuracy: 0.9980 - val_loss: 0.8135 - val_accuracy: 0.8245\n",
            "Epoch 16/22\n",
            "657/657 - 2s - loss: 0.0089 - accuracy: 0.9992 - val_loss: 0.8620 - val_accuracy: 0.8219\n",
            "Epoch 17/22\n",
            "657/657 - 2s - loss: 0.0074 - accuracy: 0.9990 - val_loss: 1.0016 - val_accuracy: 0.8189\n",
            "Epoch 18/22\n",
            "657/657 - 2s - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.9854 - val_accuracy: 0.8187\n",
            "Epoch 19/22\n",
            "657/657 - 2s - loss: 0.0041 - accuracy: 0.9995 - val_loss: 1.0661 - val_accuracy: 0.8201\n",
            "Epoch 20/22\n",
            "657/657 - 2s - loss: 0.0031 - accuracy: 0.9997 - val_loss: 1.1057 - val_accuracy: 0.8161\n",
            "Epoch 21/22\n",
            "657/657 - 2s - loss: 0.0023 - accuracy: 0.9998 - val_loss: 1.1954 - val_accuracy: 0.8154\n",
            "Epoch 22/22\n",
            "657/657 - 2s - loss: 0.0018 - accuracy: 0.9999 - val_loss: 1.2438 - val_accuracy: 0.8154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Sy3lmYygXzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "decc735a-8b01-4556-89fa-7316431ac48d"
      },
      "source": [
        "print(training_texts)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.callbacks.History object at 0x7f89afb14e10>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrpZ7X0EkDsJ",
        "colab_type": "text"
      },
      "source": [
        "# Testing Model on New sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jYnpXDWjvwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now we can predic any sentence using the model. What ever it bias to sarcastic or not\n",
        "new_sentences = ['The first step in sentence classification is to represent variable-length sentences using neural networks.', \n",
        "             'In this section, I’m going to present the concept of recurrent neural networks (RNNs), one of the most important concepts in deep NLP.', \n",
        "             'Many modern NLP models use RNNs in some way.', \n",
        "             'I’ll explain why they’re important, what they do, and introduce their simplest variant.']"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Moak1n8F3jTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_sentences = tokenizer.texts_to_sequences(new_sentences)\n",
        "paded_new_sent = pad_sequences(sequence_sentences)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXEWTs7Y4Vff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "054c2343-fa20-4932-e29b-8b44a41bc4f4"
      },
      "source": [
        "paded_new_sent"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0,     0,     0,     0,     0,     3,    54,\n",
              "         1297,     4,  1470,    10,     1,  6175,  7186,   625, 11079],\n",
              "       [    4,    19,  1972,   117,     1,  3328,     3,  4077,     2,\n",
              "        11079,    40,     2,     3,    91,   838, 18717,     4,   942],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,   452,  1672,  3569,   340,     4,   153,    89],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,  1678,\n",
              "           46,   838,    31,    95,    90,     8,  4868,    93, 13023]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5ebORd74zB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(paded_new_sent)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW9rFWqL5C7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "46fe1793-83d0-4888-983c-71e9d8d668f9"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.9035932e-12]\n",
            " [7.2136223e-03]\n",
            " [9.6239793e-01]\n",
            " [5.2537048e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR7xxt1j7DSj",
        "colab_type": "text"
      },
      "source": [
        "### Ssentiment Analysis in New sentences:\n",
        "prediction 9 indicating the 4th sentece has a high probability of sarcasm. Less than 5 indicates these sentences are not sercastic at all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwpMSY3r5HCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3rDmN7nE-FR",
        "colab_type": "text"
      },
      "source": [
        "# Training AI to create Poem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWPdahAXIDWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.compat.v2.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7HTwf4JFB14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = \"\"\"Do not go gentle into that good night,\n",
        "Old age should burn and rave at close of day;\n",
        "Rage, rage against the dying of the light.\n",
        "\n",
        "Though wise men at their end know dark is right,\n",
        "Because their words had forked no lightning they\n",
        "Do not go gentle into that good night.\n",
        "\n",
        "Good men, the last wave by, crying how bright\n",
        "Their frail deeds might have danced in a green bay,\n",
        "Rage, rage against the dying of the light.\n",
        "\n",
        "Wild men who caught and sang the sun in flight,\n",
        "And learn, too late, they grieved it on its way,\n",
        "Do not go gentle into that good night.\n",
        "\n",
        "Grave men, near death, who see with blinding sight\n",
        "Blind eyes could blaze like meteors and be gay,\n",
        "Rage, rage against the dying of the light.\n",
        "\n",
        "And you, my father, there on the sad height,\n",
        "Curse, bless, me now with your fierce tears, I pray.\n",
        "Do not go gentle into that good night.\n",
        "Rage, rage against the dying of the light\"\"\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4z5MyNZFKDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = data.lower().split('\\n')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z70oJmdpHDjl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e3b8a396-61fc-43e5-cb25-b2cea7cac5c7"
      },
      "source": [
        "corpus[0:3]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['do not go gentle into that good night,',\n",
              " 'old age should burn and rave at close of day;',\n",
              " 'rage, rage against the dying of the light.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUy_t090HFgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenized_corpus = tokenizer.fit_on_texts(corpus[:])\n",
        "\n",
        "totl_words = len(tokenizer.word_index)+1\n",
        "\n",
        "input_sequence = []\n",
        "\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequence.append(n_gram_sequence)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikbXJN6DULEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d5cb25b2-f1cf-435e-a1b2-4d60999d6531"
      },
      "source": [
        "print(input_sequence)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6, 7], [6, 7, 8], [6, 7, 8, 9], [6, 7, 8, 9, 10], [6, 7, 8, 9, 10, 11], [6, 7, 8, 9, 10, 11, 3], [6, 7, 8, 9, 10, 11, 3, 12], [24, 25], [24, 25, 26], [24, 25, 26, 27], [24, 25, 26, 27, 4], [24, 25, 26, 27, 4, 28], [24, 25, 26, 27, 4, 28, 18], [24, 25, 26, 27, 4, 28, 18, 29], [24, 25, 26, 27, 4, 28, 18, 29, 5], [24, 25, 26, 27, 4, 28, 18, 29, 5, 30], [2, 2], [2, 2, 13], [2, 2, 13, 1], [2, 2, 13, 1, 14], [2, 2, 13, 1, 14, 5], [2, 2, 13, 1, 14, 5, 1], [2, 2, 13, 1, 14, 5, 1, 15], [31, 32], [31, 32, 16], [31, 32, 16, 18], [31, 32, 16, 18, 17], [31, 32, 16, 18, 17, 33], [31, 32, 16, 18, 17, 33, 34], [31, 32, 16, 18, 17, 33, 34, 35], [31, 32, 16, 18, 17, 33, 34, 35, 36], [31, 32, 16, 18, 17, 33, 34, 35, 36, 37], [38, 17], [38, 17, 39], [38, 17, 39, 40], [38, 17, 39, 40, 41], [38, 17, 39, 40, 41, 42], [38, 17, 39, 40, 41, 42, 43], [38, 17, 39, 40, 41, 42, 43, 19], [6, 7], [6, 7, 8], [6, 7, 8, 9], [6, 7, 8, 9, 10], [6, 7, 8, 9, 10, 11], [6, 7, 8, 9, 10, 11, 3], [6, 7, 8, 9, 10, 11, 3, 12], [3, 16], [3, 16, 1], [3, 16, 1, 44], [3, 16, 1, 44, 45], [3, 16, 1, 44, 45, 46], [3, 16, 1, 44, 45, 46, 47], [3, 16, 1, 44, 45, 46, 47, 48], [3, 16, 1, 44, 45, 46, 47, 48, 49], [17, 50], [17, 50, 51], [17, 50, 51, 52], [17, 50, 51, 52, 53], [17, 50, 51, 52, 53, 54], [17, 50, 51, 52, 53, 54, 20], [17, 50, 51, 52, 53, 54, 20, 55], [17, 50, 51, 52, 53, 54, 20, 55, 56], [17, 50, 51, 52, 53, 54, 20, 55, 56, 57], [2, 2], [2, 2, 13], [2, 2, 13, 1], [2, 2, 13, 1, 14], [2, 2, 13, 1, 14, 5], [2, 2, 13, 1, 14, 5, 1], [2, 2, 13, 1, 14, 5, 1, 15], [58, 16], [58, 16, 21], [58, 16, 21, 59], [58, 16, 21, 59, 4], [58, 16, 21, 59, 4, 60], [58, 16, 21, 59, 4, 60, 1], [58, 16, 21, 59, 4, 60, 1, 61], [58, 16, 21, 59, 4, 60, 1, 61, 20], [58, 16, 21, 59, 4, 60, 1, 61, 20, 62], [4, 63], [4, 63, 64], [4, 63, 64, 65], [4, 63, 64, 65, 19], [4, 63, 64, 65, 19, 66], [4, 63, 64, 65, 19, 66, 67], [4, 63, 64, 65, 19, 66, 67, 22], [4, 63, 64, 65, 19, 66, 67, 22, 68], [4, 63, 64, 65, 19, 66, 67, 22, 68, 69], [6, 7], [6, 7, 8], [6, 7, 8, 9], [6, 7, 8, 9, 10], [6, 7, 8, 9, 10, 11], [6, 7, 8, 9, 10, 11, 3], [6, 7, 8, 9, 10, 11, 3, 12], [70, 16], [70, 16, 71], [70, 16, 71, 72], [70, 16, 71, 72, 21], [70, 16, 71, 72, 21, 73], [70, 16, 71, 72, 21, 73, 23], [70, 16, 71, 72, 21, 73, 23, 74], [70, 16, 71, 72, 21, 73, 23, 74, 75], [76, 77], [76, 77, 78], [76, 77, 78, 79], [76, 77, 78, 79, 80], [76, 77, 78, 79, 80, 81], [76, 77, 78, 79, 80, 81, 4], [76, 77, 78, 79, 80, 81, 4, 82], [76, 77, 78, 79, 80, 81, 4, 82, 83], [2, 2], [2, 2, 13], [2, 2, 13, 1], [2, 2, 13, 1, 14], [2, 2, 13, 1, 14, 5], [2, 2, 13, 1, 14, 5, 1], [2, 2, 13, 1, 14, 5, 1, 15], [4, 84], [4, 84, 85], [4, 84, 85, 86], [4, 84, 85, 86, 87], [4, 84, 85, 86, 87, 22], [4, 84, 85, 86, 87, 22, 1], [4, 84, 85, 86, 87, 22, 1, 88], [4, 84, 85, 86, 87, 22, 1, 88, 89], [90, 91], [90, 91, 92], [90, 91, 92, 93], [90, 91, 92, 93, 23], [90, 91, 92, 93, 23, 94], [90, 91, 92, 93, 23, 94, 95], [90, 91, 92, 93, 23, 94, 95, 96], [90, 91, 92, 93, 23, 94, 95, 96, 97], [90, 91, 92, 93, 23, 94, 95, 96, 97, 98], [6, 7], [6, 7, 8], [6, 7, 8, 9], [6, 7, 8, 9, 10], [6, 7, 8, 9, 10, 11], [6, 7, 8, 9, 10, 11, 3], [6, 7, 8, 9, 10, 11, 3, 12], [2, 2], [2, 2, 13], [2, 2, 13, 1], [2, 2, 13, 1, 14], [2, 2, 13, 1, 14, 5], [2, 2, 13, 1, 14, 5, 1], [2, 2, 13, 1, 14, 5, 1, 15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi18K2cFUeKZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "514dc0fe-b5a2-4d7d-8fa0-f114c196eb1d"
      },
      "source": [
        "max_sequence_len = max([len(x) for x in input_sequence])\n",
        "max_sequence_len"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi6hEMyCV1NM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "af0d5a38-718e-45ca-9d5d-391cf5031fbf"
      },
      "source": [
        "input_sequence = np.array(pad_sequences(input_sequence, maxlen=max_sequence_len, padding='pre'))\n",
        "input_sequence"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  6,  7],\n",
              "       [ 0,  0,  0, ...,  6,  7,  8],\n",
              "       [ 0,  0,  0, ...,  7,  8,  9],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  1, 14,  5],\n",
              "       [ 0,  0,  0, ..., 14,  5,  1],\n",
              "       [ 0,  0,  2, ...,  5,  1, 15]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsHaIV2pWWo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = input_sequence[:,:-1]\n",
        "labels = input_sequence[:,-1]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUx5z-0dXTz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "a636fa71-5f41-4f3e-eae0-27194cbeab32"
      },
      "source": [
        "labels"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  8,  9, 10, 11,  3, 12, 25, 26, 27,  4, 28, 18, 29,  5, 30,  2,\n",
              "       13,  1, 14,  5,  1, 15, 32, 16, 18, 17, 33, 34, 35, 36, 37, 17, 39,\n",
              "       40, 41, 42, 43, 19,  7,  8,  9, 10, 11,  3, 12, 16,  1, 44, 45, 46,\n",
              "       47, 48, 49, 50, 51, 52, 53, 54, 20, 55, 56, 57,  2, 13,  1, 14,  5,\n",
              "        1, 15, 16, 21, 59,  4, 60,  1, 61, 20, 62, 63, 64, 65, 19, 66, 67,\n",
              "       22, 68, 69,  7,  8,  9, 10, 11,  3, 12, 16, 71, 72, 21, 73, 23, 74,\n",
              "       75, 77, 78, 79, 80, 81,  4, 82, 83,  2, 13,  1, 14,  5,  1, 15, 84,\n",
              "       85, 86, 87, 22,  1, 88, 89, 91, 92, 93, 23, 94, 95, 96, 97, 98,  7,\n",
              "        8,  9, 10, 11,  3, 12,  2, 13,  1, 14,  5,  1, 15], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Oxo4HNKXXcu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "502af7eb-7712-444d-f590-49e791291e3e"
      },
      "source": [
        "y = tf.keras.utils.to_categorical(labels, num_classes=totl_words)\n",
        "y"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3vM2EpiZscB",
        "colab_type": "text"
      },
      "source": [
        "# Now training Neural network with above data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vODAve9yL9M1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Dense,LSTM"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0po0ET41ZFV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpyIp6nwL5LR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Embedding(totl_words, 99, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(50, input_shape=(360,1))))\n",
        "model.add(Dense(totl_words, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XSbuIzZCiJL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "8b7191b1-4e30-4621-a9bd-5ace6435f2ad"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 9, 99)             9801      \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 100)               60000     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 99)                9999      \n",
            "=================================================================\n",
            "Total params: 79,800\n",
            "Trainable params: 79,800\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeqO3vlwNPmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fabf8a5e-c8cc-4990-d281-536048711c73"
      },
      "source": [
        "history = model.fit(x, y, epochs=100, verbose=1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6525 - accuracy: 0.9866\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6297 - accuracy: 0.9799\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6068 - accuracy: 0.9866\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5862 - accuracy: 0.9799\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5622 - accuracy: 0.9799\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5405 - accuracy: 0.9799\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5196 - accuracy: 0.9933\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5008 - accuracy: 0.9933\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4826 - accuracy: 0.9866\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4674 - accuracy: 0.9933\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4547 - accuracy: 0.9866\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4461 - accuracy: 0.9866\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4288 - accuracy: 0.9933\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4150 - accuracy: 0.9933\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3985 - accuracy: 0.9933\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3846 - accuracy: 0.9933\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3712 - accuracy: 0.9933\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3610 - accuracy: 0.9933\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3485 - accuracy: 0.9933\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3377 - accuracy: 0.9933\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3269 - accuracy: 0.9933\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3176 - accuracy: 0.9933\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3070 - accuracy: 0.9933\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2986 - accuracy: 0.9933\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2895 - accuracy: 0.9933\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2809 - accuracy: 0.9933\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2734 - accuracy: 0.9866\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2655 - accuracy: 0.9933\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2588 - accuracy: 0.9933\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2507 - accuracy: 0.9933\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2448 - accuracy: 0.9866\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2383 - accuracy: 0.9933\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2311 - accuracy: 0.9933\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2262 - accuracy: 0.9933\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2199 - accuracy: 0.9933\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2141 - accuracy: 0.9933\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2092 - accuracy: 0.9933\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2048 - accuracy: 0.9933\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2001 - accuracy: 0.9933\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1946 - accuracy: 0.9933\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1909 - accuracy: 0.9933\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1855 - accuracy: 0.9933\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1814 - accuracy: 0.9933\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1769 - accuracy: 0.9933\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1731 - accuracy: 0.9933\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1694 - accuracy: 0.9933\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1662 - accuracy: 0.9933\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1624 - accuracy: 0.9933\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1586 - accuracy: 0.9933\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1548 - accuracy: 0.9933\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1518 - accuracy: 0.9933\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1488 - accuracy: 0.9933\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1466 - accuracy: 0.9933\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1435 - accuracy: 0.9933\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1403 - accuracy: 0.9933\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1374 - accuracy: 0.9933\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1346 - accuracy: 0.9866\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1316 - accuracy: 0.9933\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1291 - accuracy: 0.9933\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1266 - accuracy: 0.9933\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1245 - accuracy: 0.9933\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1221 - accuracy: 0.9933\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1198 - accuracy: 0.9933\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1176 - accuracy: 0.9933\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1154 - accuracy: 0.9933\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1135 - accuracy: 0.9933\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1115 - accuracy: 0.9933\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1090 - accuracy: 0.9933\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1073 - accuracy: 0.9933\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1052 - accuracy: 0.9933\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1037 - accuracy: 0.9933\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1019 - accuracy: 0.9933\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1003 - accuracy: 0.9933\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0984 - accuracy: 0.9933\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0970 - accuracy: 0.9866\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0952 - accuracy: 0.9933\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0938 - accuracy: 0.9933\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0921 - accuracy: 0.9933\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0914 - accuracy: 0.9933\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0895 - accuracy: 0.9933\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0883 - accuracy: 0.9933\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0869 - accuracy: 0.9933\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0852 - accuracy: 0.9933\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0839 - accuracy: 0.9933\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9933\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0812 - accuracy: 0.9933\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0802 - accuracy: 0.9933\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0789 - accuracy: 0.9933\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0777 - accuracy: 0.9933\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0768 - accuracy: 0.9866\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0754 - accuracy: 0.9933\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0747 - accuracy: 0.9866\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0733 - accuracy: 0.9933\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0723 - accuracy: 0.9933\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0714 - accuracy: 0.9933\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0704 - accuracy: 0.9933\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0693 - accuracy: 0.9933\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0685 - accuracy: 0.9933\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0676 - accuracy: 0.9933\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0667 - accuracy: 0.9933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVo3CWzlKlMT",
        "colab_type": "text"
      },
      "source": [
        "# Poet by the model by prediction of next word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ9SuGQEAjly",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b2ebbd1b-3420-4ae2-9784-377a319af43f"
      },
      "source": [
        "seed = 'Do not go gentle into that good night'\n",
        "next_word = 21\n",
        "\n",
        "for _ in range(next_word):\n",
        "  token_list = tokenizer.texts_to_sequences([seed])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len, padding='pre')\n",
        "  prediction = model.predict_classes(token_list , verbose=0)\n",
        "  output = ''\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == prediction:\n",
        "      output = word\n",
        "      break\n",
        "  seed = ' ' + output\n",
        "print(seed)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-30-51a17a3795e3>:7: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 9) for input Tensor(\"embedding_input:0\", shape=(None, 9), dtype=float32), but it was called on an input with incompatible shape (None, 10).\n",
            " wise\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3csKxFMmOVLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}