{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP - Natural Language Processing Using TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP9Ejj3DvLKCm7vkAbK6ypJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abidshafee/google.colaboratory_projects/blob/master/NLP_Natural_Language_Processing_Using_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmy1OmLTNRIW",
        "colab_type": "text"
      },
      "source": [
        "# Tokenization\n",
        "api involves: **Tokenizer** from **tensorflow->compat.v2->keras->preprocessing.txt**\n",
        "\n",
        "Given sentences encoding into numbers is calles Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYDGN2atQPZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.compat.v2.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.txt import Tokenizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdSK87gTNPQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = ['The first step in sentence classification is to represent variable-length sentences using neural networks.', 'In this section, I’m going to present the concept of recurrent neural networks (RNNs), one of the most important concepts in deep NLP.', 'Many modern NLP models use RNNs in some way.', 'I’ll explain why they’re important, what they do, and introduce their simplest variant.']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5YSKnz5Yxol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=100, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "# print(word_index)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EZP9IKpaRpY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "719a50b2-4c91-4e55-c8bf-2b797132244a"
      },
      "source": [
        "word_index.keys()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['<OOV>', 'in', 'the', 'to', 'neural', 'networks', 'of', 'rnns', 'important', 'nlp', 'first', 'step', 'sentence', 'classification', 'is', 'represent', 'variable', 'length', 'sentences', 'using', 'this', 'section', 'i’m', 'going', 'present', 'concept', 'recurrent', 'one', 'most', 'concepts', 'deep', 'many', 'modern', 'models', 'use', 'some', 'way', 'i’ll', 'explain', 'why', 'they’re', 'what', 'they', 'do', 'and', 'introduce', 'their', 'simplest', 'variant'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FGox-YXyl1x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c3ae2915-4948-4b36-d3ed-debd29737939"
      },
      "source": [
        "word_index.values()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf-BKLTKxOTX",
        "colab_type": "text"
      },
      "source": [
        "# Organizing text by Sequencing - Turning Sentences into data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXKts2FbbmWW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a462bf7a-23d4-4fcb-f508-1ee485dc6236"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print(sequences)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3, 11, 12, 2, 13, 14, 15, 4, 16, 17, 18, 19, 20, 5, 6], [2, 21, 22, 23, 24, 4, 25, 3, 26, 7, 27, 5, 6, 8, 28, 7, 3, 29, 9, 30, 2, 31, 10], [32, 33, 10, 34, 35, 8, 2, 36, 37], [38, 39, 40, 41, 9, 42, 43, 44, 45, 46, 47, 48, 49]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsyJy28E4iFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1ffd32be-dfdc-4f51-962e-b83c078a5f8c"
      },
      "source": [
        "# pad_sequences() is a method to handle sentences of different lengths\n",
        "# best way to handle sentence length is using raggedtensor, we might discuss it in another scope\n",
        "# but for simplicity we uses here the pad_sequence() to deal with sentence length\n",
        "padded = pad_sequences(sequences)\n",
        "print(padded)\n",
        "\n",
        "# pad_sequences accept parameters are follows: \n",
        "#  - padding='post' - will add 0s after the sentences\n",
        "#  - maxlen=5 - maxlen parameter specify the desire lengh\n",
        "#  - truncating='post' - specify the choping off the later post if sentence exided 'maxlen'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  0  0  0  0  0  3 11 12  2 13 14 15  4 16 17 18 19 20  5  6]\n",
            " [ 2 21 22 23 24  4 25  3 26  7 27  5  6  8 28  7  3 29  9 30  2 31 10]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 32 33 10 34 35  8  2 36 37]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 38 39 40 41  9 42 43 44 45 46 47 48 49]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qODYjsFnGAA5",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis - recognize sentiment in text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "905vSPop9dwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-_OKs1QOn__",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "de7bf117-789d-4eb0-d998-83a800ce2e97"
      },
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-598e2cea-fc45-4608-8ef6-51c68432008d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-598e2cea-fc45-4608-8ef6-51c68432008d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sarcasm.json to sarcasm.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s12aJIZDO9ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('sarcasm.json', 'r') as f:\n",
        "  datastore = json.load(f)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29awEkOpPcTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = []\n",
        "labels = []\n",
        "urls = []\n",
        "\n",
        "for item in datastore:\n",
        "  sentences.append(item['headline'])\n",
        "  labels.append(item['is_sarcastic'])\n",
        "  urls.append(item['article_link'])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-82hi1n2Pof7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentences"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQTaIGPtS6Ts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85cd4ee1-7961-455c-b593-6764ab2eb17f"
      },
      "source": [
        "# labels\n",
        "# urls\n",
        "len(labels)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26709"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw2iAddzVT_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WBawwW65f30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now turning the sentences sequence of token\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "paded = pad_sequences(sequences, padding='post')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQY1jPcD9jmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64b0755b-d749-4104-dba7-5ea3c4b9bda3"
      },
      "source": [
        "len(sequences)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26709"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19hDmdqn5sFw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e276797a-ce41-478b-d0dd-6cb17981ab33"
      },
      "source": [
        "paded[1]\n",
        "# paded.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   4, 8435, 3338, 2746,   22,    2,  166, 8436,  416, 3112,    6,\n",
              "        258,    9, 1002,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVyNGcq48_MQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83223fa6-0c5a-4a0f-d48e-096a03fb571f"
      },
      "source": [
        "paded.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26709, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FSWRcwb6tOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now spliting data into traning and testing sets\n",
        "# let training_size = 80% of data; 26709*80% using python slicing\n",
        "\n",
        "training_size = 21000\n",
        "\n",
        "training_sentences = sentences[:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "\n",
        "# spliting labels into training and testing sets\n",
        "training_labels = labels[:training_size]\n",
        "testing_labels = labels[training_size:]\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW2Q23dSDc6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now tekenize trainig and testing set seperately\n",
        "\n",
        "tokenizer = Tokenizer(num_words=training_size, oov_token=None)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwLhugV9VXjO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "634eac53-879d-47f7-85b0-8fbf6b27fef9"
      },
      "source": [
        "# word_index\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_paded = pad_sequences(training_sequences)\n",
        "training_paded"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,     5,  2711,  9172],\n",
              "       [    0,     0,     0, ...,   254,     8,   945],\n",
              "       [    0,     0,     0, ...,    44,     1,  9173],\n",
              "       ...,\n",
              "       [    0,     0,     0, ..., 12473,  5960,   496],\n",
              "       [    0,     0,     0, ...,     3,   363,   311],\n",
              "       [    0,     0,     0, ...,    19,  3769,   937]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn11YXKqXiXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9283e25d-21ff-4668-fa71-3431148810e5"
      },
      "source": [
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_paded = pad_sequences(testing_sequences)\n",
        "testing_paded"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,   369,  1316,  5075],\n",
              "       [    0,     0,     0, ...,     0,     0,  5478],\n",
              "       [    0,     0,     0, ..., 13430,     7, 14891],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,     0,     8,    67],\n",
              "       [    0,     0,     0, ...,  1724,  3788,  3483],\n",
              "       [    0,     0,     0, ...,     5,     3,   800]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGed_DlsiMOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# converting to numpy array explicitely for recent version of tf\n",
        "training_paded = np.array(training_paded)\n",
        "training_labels = np.array(training_labels)\n",
        "testing_paded = np.array(testing_paded)\n",
        "testing_labels = np.array(testing_labels)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGtExJSAaD5_",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS5ymXZOYz5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(training_size, output_dim=11),\n",
        "                             tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                             tf.keras.layers.Dense(21, activation = 'relu'),\n",
        "                             tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8voEWYCickQJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "e74581ed-e55a-420b-c015-47b300c20ff1"
      },
      "source": [
        "epoch_no = 22\n",
        "training_texts = model.fit(training_paded, training_labels, epochs=epoch_no,\n",
        "                           validation_data=(testing_paded, testing_labels), verbose=2)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/22\n",
            "657/657 - 2s - loss: 0.6224 - accuracy: 0.6523 - val_loss: 0.4501 - val_accuracy: 0.8205\n",
            "Epoch 2/22\n",
            "657/657 - 2s - loss: 0.3370 - accuracy: 0.8680 - val_loss: 0.3452 - val_accuracy: 0.8550\n",
            "Epoch 3/22\n",
            "657/657 - 2s - loss: 0.2360 - accuracy: 0.9095 - val_loss: 0.3336 - val_accuracy: 0.8583\n",
            "Epoch 4/22\n",
            "657/657 - 2s - loss: 0.1781 - accuracy: 0.9352 - val_loss: 0.3426 - val_accuracy: 0.8600\n",
            "Epoch 5/22\n",
            "657/657 - 2s - loss: 0.1377 - accuracy: 0.9526 - val_loss: 0.3615 - val_accuracy: 0.8564\n",
            "Epoch 6/22\n",
            "657/657 - 2s - loss: 0.1062 - accuracy: 0.9659 - val_loss: 0.3902 - val_accuracy: 0.8534\n",
            "Epoch 7/22\n",
            "657/657 - 2s - loss: 0.0827 - accuracy: 0.9744 - val_loss: 0.4290 - val_accuracy: 0.8466\n",
            "Epoch 8/22\n",
            "657/657 - 2s - loss: 0.0650 - accuracy: 0.9810 - val_loss: 0.4684 - val_accuracy: 0.8441\n",
            "Epoch 9/22\n",
            "657/657 - 2s - loss: 0.0493 - accuracy: 0.9863 - val_loss: 0.5150 - val_accuracy: 0.8392\n",
            "Epoch 10/22\n",
            "657/657 - 2s - loss: 0.0378 - accuracy: 0.9907 - val_loss: 0.5866 - val_accuracy: 0.8345\n",
            "Epoch 11/22\n",
            "657/657 - 2s - loss: 0.0301 - accuracy: 0.9926 - val_loss: 0.6142 - val_accuracy: 0.8331\n",
            "Epoch 12/22\n",
            "657/657 - 2s - loss: 0.0220 - accuracy: 0.9953 - val_loss: 0.6664 - val_accuracy: 0.8306\n",
            "Epoch 13/22\n",
            "657/657 - 2s - loss: 0.0163 - accuracy: 0.9968 - val_loss: 0.7331 - val_accuracy: 0.8283\n",
            "Epoch 14/22\n",
            "657/657 - 2s - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.7872 - val_accuracy: 0.8254\n",
            "Epoch 15/22\n",
            "657/657 - 2s - loss: 0.0090 - accuracy: 0.9986 - val_loss: 0.8474 - val_accuracy: 0.8224\n",
            "Epoch 16/22\n",
            "657/657 - 2s - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.9112 - val_accuracy: 0.8215\n",
            "Epoch 17/22\n",
            "657/657 - 2s - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.9719 - val_accuracy: 0.8222\n",
            "Epoch 18/22\n",
            "657/657 - 2s - loss: 0.0039 - accuracy: 0.9996 - val_loss: 1.0384 - val_accuracy: 0.8203\n",
            "Epoch 19/22\n",
            "657/657 - 2s - loss: 0.0028 - accuracy: 0.9996 - val_loss: 1.1074 - val_accuracy: 0.8182\n",
            "Epoch 20/22\n",
            "657/657 - 2s - loss: 0.0021 - accuracy: 0.9998 - val_loss: 1.2019 - val_accuracy: 0.8140\n",
            "Epoch 21/22\n",
            "657/657 - 2s - loss: 0.0014 - accuracy: 0.9999 - val_loss: 1.2305 - val_accuracy: 0.8177\n",
            "Epoch 22/22\n",
            "657/657 - 2s - loss: 8.9002e-04 - accuracy: 0.9999 - val_loss: 1.2928 - val_accuracy: 0.8170\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Sy3lmYygXzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24d42dae-c861-42db-953e-1412ad358015"
      },
      "source": [
        "print(training_texts)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.callbacks.History object at 0x7ffb8d425e10>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrpZ7X0EkDsJ",
        "colab_type": "text"
      },
      "source": [
        "# Testing Model on New sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jYnpXDWjvwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now we can predic any sentence using the model. What ever it bias to sarcastic or not\n",
        "new_sentences = ['The first step in sentence classification is to represent variable-length sentences using neural networks.', \n",
        "             'In this section, I’m going to present the concept of recurrent neural networks (RNNs), one of the most important concepts in deep NLP.', \n",
        "             'Many modern NLP models use RNNs in some way.', \n",
        "             'I’ll explain why they’re important, what they do, and introduce their simplest variant.']"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Moak1n8F3jTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_sentences = tokenizer.texts_to_sequences(new_sentences)\n",
        "paded_new_sent = pad_sequences(sequence_sentences)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXEWTs7Y4Vff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "84b23054-f006-4a6f-8d6d-1f60e370a1ec"
      },
      "source": [
        "paded_new_sent"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0,     0,     0,     0,     0,     3,    54,\n",
              "         1297,     4,  1470,    10,     1,  6175,  7186,   625, 11079],\n",
              "       [    4,    19,  1972,   117,     1,  3328,     3,  4077,     2,\n",
              "        11079,    40,     2,     3,    91,   838, 18717,     4,   942],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,   452,  1672,  3569,   340,     4,   153,    89],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,  1678,\n",
              "           46,   838,    31,    95,    90,     8,  4868,    93, 13023]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5ebORd74zB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(paded_new_sent)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW9rFWqL5C7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6ee609da-3043-4447-ec87-80d1ba759ee9"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.4435978e-08]\n",
            " [6.3161417e-05]\n",
            " [9.9546933e-01]\n",
            " [9.8274875e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR7xxt1j7DSj",
        "colab_type": "text"
      },
      "source": [
        "### Ssentiment Analysis in New sentences:\n",
        "prediction 9 indicating the 4th sentece has a high probability of sarcasm. Less than 5 indicates these sentences are not sercastic at all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwpMSY3r5HCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3rDmN7nE-FR",
        "colab_type": "text"
      },
      "source": [
        "# Training AI to create Poem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7HTwf4JFB14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = \"\"\"Do not go gentle into that good night,\n",
        "Old age should burn and rave at close of day;\n",
        "Rage, rage against the dying of the light.\n",
        "\n",
        "Though wise men at their end know dark is right,\n",
        "Because their words had forked no lightning they\n",
        "Do not go gentle into that good night.\n",
        "\n",
        "Good men, the last wave by, crying how bright\n",
        "Their frail deeds might have danced in a green bay,\n",
        "Rage, rage against the dying of the light.\n",
        "\n",
        "Wild men who caught and sang the sun in flight,\n",
        "And learn, too late, they grieved it on its way,\n",
        "Do not go gentle into that good night.\n",
        "\n",
        "Grave men, near death, who see with blinding sight\n",
        "Blind eyes could blaze like meteors and be gay,\n",
        "Rage, rage against the dying of the light.\n",
        "\n",
        "And you, my father, there on the sad height,\n",
        "Curse, bless, me now with your fierce tears, I pray.\n",
        "Do not go gentle into that good night.\n",
        "Rage, rage against the dying of the light\"\"\""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4z5MyNZFKDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = data.lower().split('\\n')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z70oJmdpHDjl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "55a685d4-b457-4201-92be-e5cdeb47d73a"
      },
      "source": [
        "corpus[0:3]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['do not go gentle into that good night,',\n",
              " 'old age should burn and rave at close of day;',\n",
              " 'rage, rage against the dying of the light.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUy_t090HFgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenized_corpus = tokenizer.fit_on_texts(corpus[:])\n",
        "\n",
        "input_sequence = []\n",
        "\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequence.append(n_gram_sequence)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikbXJN6DULEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f24aa88f-b56a-4d2a-8b3b-9f3b73734e75"
      },
      "source": [
        "print(input_sequence)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6, 7], [6, 7, 8], [6, 7, 8, 9], [6, 7, 8, 9, 10], [6, 7, 8, 9, 10, 11], [6, 7, 8, 9, 10, 11, 3], [6, 7, 8, 9, 10, 11, 3, 12], [24, 25], [24, 25, 26], [24, 25, 26, 27], [24, 25, 26, 27, 4], [24, 25, 26, 27, 4, 28], [24, 25, 26, 27, 4, 28, 18], [24, 25, 26, 27, 4, 28, 18, 29], [24, 25, 26, 27, 4, 28, 18, 29, 5], [24, 25, 26, 27, 4, 28, 18, 29, 5, 30], [2, 2], [2, 2, 13], [2, 2, 13, 1], [2, 2, 13, 1, 14], [2, 2, 13, 1, 14, 5], [2, 2, 13, 1, 14, 5, 1], [2, 2, 13, 1, 14, 5, 1, 15], [31, 32], [31, 32, 16], [31, 32, 16, 18], [31, 32, 16, 18, 17], [31, 32, 16, 18, 17, 33], [31, 32, 16, 18, 17, 33, 34], [31, 32, 16, 18, 17, 33, 34, 35], [31, 32, 16, 18, 17, 33, 34, 35, 36], [31, 32, 16, 18, 17, 33, 34, 35, 36, 37], [38, 17], [38, 17, 39], [38, 17, 39, 40], [38, 17, 39, 40, 41], [38, 17, 39, 40, 41, 42], [38, 17, 39, 40, 41, 42, 43], [38, 17, 39, 40, 41, 42, 43, 19], [6, 7], [6, 7, 8], [6, 7, 8, 9], [6, 7, 8, 9, 10], [6, 7, 8, 9, 10, 11], [6, 7, 8, 9, 10, 11, 3], [6, 7, 8, 9, 10, 11, 3, 12], [3, 16], [3, 16, 1], [3, 16, 1, 44], [3, 16, 1, 44, 45], [3, 16, 1, 44, 45, 46], [3, 16, 1, 44, 45, 46, 47], [3, 16, 1, 44, 45, 46, 47, 48], [3, 16, 1, 44, 45, 46, 47, 48, 49], [17, 50], [17, 50, 51], [17, 50, 51, 52], [17, 50, 51, 52, 53], [17, 50, 51, 52, 53, 54], [17, 50, 51, 52, 53, 54, 20], [17, 50, 51, 52, 53, 54, 20, 55], [17, 50, 51, 52, 53, 54, 20, 55, 56], [17, 50, 51, 52, 53, 54, 20, 55, 56, 57], [2, 2], [2, 2, 13], [2, 2, 13, 1], [2, 2, 13, 1, 14], [2, 2, 13, 1, 14, 5], [2, 2, 13, 1, 14, 5, 1], [2, 2, 13, 1, 14, 5, 1, 15], [58, 16], [58, 16, 21], [58, 16, 21, 59], [58, 16, 21, 59, 4], [58, 16, 21, 59, 4, 60], [58, 16, 21, 59, 4, 60, 1], [58, 16, 21, 59, 4, 60, 1, 61], [58, 16, 21, 59, 4, 60, 1, 61, 20], [58, 16, 21, 59, 4, 60, 1, 61, 20, 62], [4, 63], [4, 63, 64], [4, 63, 64, 65], [4, 63, 64, 65, 19], [4, 63, 64, 65, 19, 66], [4, 63, 64, 65, 19, 66, 67], [4, 63, 64, 65, 19, 66, 67, 22], [4, 63, 64, 65, 19, 66, 67, 22, 68], [4, 63, 64, 65, 19, 66, 67, 22, 68, 69], [6, 7], [6, 7, 8], [6, 7, 8, 9], [6, 7, 8, 9, 10], [6, 7, 8, 9, 10, 11], [6, 7, 8, 9, 10, 11, 3], [6, 7, 8, 9, 10, 11, 3, 12], [70, 16], [70, 16, 71], [70, 16, 71, 72], [70, 16, 71, 72, 21], [70, 16, 71, 72, 21, 73], [70, 16, 71, 72, 21, 73, 23], [70, 16, 71, 72, 21, 73, 23, 74], [70, 16, 71, 72, 21, 73, 23, 74, 75], [76, 77], [76, 77, 78], [76, 77, 78, 79], [76, 77, 78, 79, 80], [76, 77, 78, 79, 80, 81], [76, 77, 78, 79, 80, 81, 4], [76, 77, 78, 79, 80, 81, 4, 82], [76, 77, 78, 79, 80, 81, 4, 82, 83], [2, 2], [2, 2, 13], [2, 2, 13, 1], [2, 2, 13, 1, 14], [2, 2, 13, 1, 14, 5], [2, 2, 13, 1, 14, 5, 1], [2, 2, 13, 1, 14, 5, 1, 15], [4, 84], [4, 84, 85], [4, 84, 85, 86], [4, 84, 85, 86, 87], [4, 84, 85, 86, 87, 22], [4, 84, 85, 86, 87, 22, 1], [4, 84, 85, 86, 87, 22, 1, 88], [4, 84, 85, 86, 87, 22, 1, 88, 89], [90, 91], [90, 91, 92], [90, 91, 92, 93], [90, 91, 92, 93, 23], [90, 91, 92, 93, 23, 94], [90, 91, 92, 93, 23, 94, 95], [90, 91, 92, 93, 23, 94, 95, 96], [90, 91, 92, 93, 23, 94, 95, 96, 97], [90, 91, 92, 93, 23, 94, 95, 96, 97, 98], [6, 7], [6, 7, 8], [6, 7, 8, 9], [6, 7, 8, 9, 10], [6, 7, 8, 9, 10, 11], [6, 7, 8, 9, 10, 11, 3], [6, 7, 8, 9, 10, 11, 3, 12], [2, 2], [2, 2, 13], [2, 2, 13, 1], [2, 2, 13, 1, 14], [2, 2, 13, 1, 14, 5], [2, 2, 13, 1, 14, 5, 1], [2, 2, 13, 1, 14, 5, 1, 15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi18K2cFUeKZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecdea546-adbc-400a-bb51-54893ae426f4"
      },
      "source": [
        "max_sequence_len = max([len(x) for x in input_sequence])\n",
        "max_sequence_len"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi6hEMyCV1NM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8d7a8020-5316-428f-8405-1cb5f5cae4ec"
      },
      "source": [
        "input_sequence = np.array(pad_sequences(input_sequence, maxlen=max_sequence_len, padding='pre'))\n",
        "input_sequence"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  6,  7],\n",
              "       [ 0,  0,  0, ...,  6,  7,  8],\n",
              "       [ 0,  0,  0, ...,  7,  8,  9],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  1, 14,  5],\n",
              "       [ 0,  0,  0, ..., 14,  5,  1],\n",
              "       [ 0,  0,  2, ...,  5,  1, 15]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsHaIV2pWWo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = input_sequence[:,:-1]\n",
        "labels = input_sequence[:,-1]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUx5z-0dXTz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "da9312fa-1593-48f8-eb60-56dfdaa03aef"
      },
      "source": [
        "labels"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  8,  9, 10, 11,  3, 12, 25, 26, 27,  4, 28, 18, 29,  5, 30,  2,\n",
              "       13,  1, 14,  5,  1, 15, 32, 16, 18, 17, 33, 34, 35, 36, 37, 17, 39,\n",
              "       40, 41, 42, 43, 19,  7,  8,  9, 10, 11,  3, 12, 16,  1, 44, 45, 46,\n",
              "       47, 48, 49, 50, 51, 52, 53, 54, 20, 55, 56, 57,  2, 13,  1, 14,  5,\n",
              "        1, 15, 16, 21, 59,  4, 60,  1, 61, 20, 62, 63, 64, 65, 19, 66, 67,\n",
              "       22, 68, 69,  7,  8,  9, 10, 11,  3, 12, 16, 71, 72, 21, 73, 23, 74,\n",
              "       75, 77, 78, 79, 80, 81,  4, 82, 83,  2, 13,  1, 14,  5,  1, 15, 84,\n",
              "       85, 86, 87, 22,  1, 88, 89, 91, 92, 93, 23, 94, 95, 96, 97, 98,  7,\n",
              "        8,  9, 10, 11,  3, 12,  2, 13,  1, 14,  5,  1, 15], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Oxo4HNKXXcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}